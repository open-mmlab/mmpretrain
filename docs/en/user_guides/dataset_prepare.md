# Dataset Prepare

MMClassification supports following datasets:

- [CustomDataset](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#custom-dataset)
- [ImageNet](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#imagenet)
  - ImageNet-1k
  - ImageNet-21k
- [CIFAR](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#cifar)
  - CIFAR10
  - CIFAR100
- [MINIST](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#mnist)
  - MINIST
  - FashionMNIST
- [CUB](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#cub)
- [VOC](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#voc)

If your dataset is not in the abvove list, you could reorganize the format of your dataset to adapt to **`CustomDataset`**.

## Customize datasets by reorganizing data

`CustomDataset` supports the following three data formats:

### Subfolder Format

The sub-folder format distinguishes the categories of pictures by folders. As follows, class_1 and class_2 represent different categories.

```text
data_prefix/
├── class_1     # It is recommended to use the category name as the folder
│   ├── xxx.png
│   ├── xxy.png
│   └── ...
├── class_2
│   ├── 123.png
│   ├── 124.png
│   └── ...
```

The 'data_prefix' needs to be specified in the configuration file, and not specify the `ann_file`, as follows:

```python
dataset_cfg=dict(
    type='CustomDataset',
    data_prefix='path/to/data_prefix,
    pipeline=transfrom_list)
```

### Text Annotation File Format

The text annotation file format mainly uses text files to store category information, `data_prefix` stores images, and `ann_file` stores annotation category information.

In the following case, the dataset directory is as follows:

```text
data_root/
├── meta/
│   ├── ann_file
│   └── ...
├── data_prefix/
│   ├── folder_1
│   │   ├── xxx.png
│   │   ├── xxy.png
│   │   └── ...
│   ├── 123.png
│   ├── nsdf3.png
│   └── ...
```

The annotation file `ann_file` contains ordinary text, which is divided into two columns, the first column is the image path, and the second column is the serial number of the **category**. as follows:

```text
folder_1/xxx.png 0
folder_1/xxy.png 1
123.png 1
nsdf3.png 2
...
```

In addition, you need to specify the `classes` field in dataset config, such as:

```python
dataset_cfg=dict(
    type='CustomDataset',
    ann_file='path/to/ann_file',
    data_prefix='path/to/data_prefix',
    classes=['A', 'B', 'C', 'D'....]
    pipeline=transfrom_list)
```

```{note}
The value of ground-truth labels should fall in range `[0, num_classes - 1]`.
```

```{note}
If the ``ann_file`` is not specified, the dataset will be generated by the first way, otherwise, try the second way.
```

### OpenMMLab 2.0 Dataset Format Specification

In order to facilitate the training of multi-task algorithm models, we unify the dataset interfaces of different tasks. OpenMMLab has formulated the **OpenMMLab 2.0 Dataset Format Specification**. When starting a trainning task, the users can choose to convert their dataset annotation into the specified format, and use the algorithm library of OpenMMLab to perform algorithm training and testing based on the data annotation file.

The OpenMMLab 2.0 Dataset Format Specification stipulates that the annotation file must be in `json` or `yaml`, `yml`, `pickle` or `pkl` format; the dictionary stored in the annotation file must contain `metainfo` and `data_list` fields, The value of `metainfo` is a dictionary, which contains the meta information of the dataset; and the value of `data_list` is a list, each element in the list is a dictionary, the dictionary defines a raw data, each raw data contains a or several training/testing samples.

The following is an example of a JSON annotation file (in this example each raw data contains only one train/test sample):

```json

{
    'metainfo':
        {
            'classes': ('cat', 'dog'), # the category index of 'cat' is 0 and 'dog' is 1.
            ...
        },
    'data_list':
        [
            {
                'img_path': "xxx/xxx_0.jpg",
                'img_label': 0,
                ...
            },
            {
                'img_path': "xxx/xxx_1.jpg",
                'img_label': 1,
                ...
            },
            ...
        ]
}
```

At the same time, it is assumed that the data set storage path is as follows:

```text
data
├── annotations
│   ├── train.json
├── train
│   ├── xxx/xxx_0.jpg
│   ├── xxx/xxx_1.jpg
│   ├── ...
```

Build from the following dictionaries:

```python
dataset_cfg=dict(
    type='CustomDataset',
    ann_file='path/to/ann_file_path',
    data_prefix='path/to/images_folder',
    pipeline=transfrom_list)
```

## DatasetWrapper

The following datawrappers are supported in MMEngine, you can refer to [MMEngine tutorial](TODO:) to learn how to use it.
  
- [ConcatDataset](TODO:)
- [RepeatDataset](TODO:)
- [ClassBalancedDataset](TODO:)

The MMClassification also support [KFoldDataset](https://mmclassification.readthedocs.io/en/1.x/api/datasets.html#kfoldfataset).
